{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install mlflow","metadata":{"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting mlflow\n  Downloading mlflow-1.17.0-py3-none-any.whl (14.2 MB)\n\u001b[K     |████████████████████████████████| 14.2 MB 316 kB/s eta 0:00:01    |███████████████████▌            | 8.6 MB 5.4 MB/s eta 0:00:02\n\u001b[?25hRequirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from mlflow) (2021.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from mlflow) (1.19.5)\nCollecting querystring-parser\n  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\nRequirement already satisfied: requests>=2.17.3 in /opt/conda/lib/python3.7/site-packages (from mlflow) (2.25.1)\nCollecting gunicorn\n  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n\u001b[K     |████████████████████████████████| 79 kB 4.6 MB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: sqlparse>=0.3.1 in /opt/conda/lib/python3.7/site-packages (from mlflow) (0.4.1)\nCollecting databricks-cli>=0.8.7\n  Downloading databricks-cli-0.14.3.tar.gz (54 kB)\n\u001b[K     |████████████████████████████████| 54 kB 1.9 MB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from mlflow) (1.1.5)\nRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.7/site-packages (from mlflow) (1.6.0)\nRequirement already satisfied: Flask in /opt/conda/lib/python3.7/site-packages (from mlflow) (1.1.2)\nCollecting alembic<=1.4.1\n  Downloading alembic-1.4.1.tar.gz (1.1 MB)\n\u001b[K     |████████████████████████████████| 1.1 MB 10.5 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: docker>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from mlflow) (4.4.4)\nRequirement already satisfied: entrypoints in /opt/conda/lib/python3.7/site-packages (from mlflow) (0.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from mlflow) (5.3.1)\nRequirement already satisfied: gitpython>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from mlflow) (3.1.14)\nCollecting prometheus-flask-exporter\n  Downloading prometheus_flask_exporter-0.18.2.tar.gz (22 kB)\nRequirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from mlflow) (3.15.8)\nRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.7/site-packages (from mlflow) (7.1.2)\nRequirement already satisfied: sqlalchemy in /opt/conda/lib/python3.7/site-packages (from mlflow) (1.4.3)\nRequirement already satisfied: Mako in /opt/conda/lib/python3.7/site-packages (from alembic<=1.4.1->mlflow) (1.1.4)\nRequirement already satisfied: python-editor>=0.3 in /opt/conda/lib/python3.7/site-packages (from alembic<=1.4.1->mlflow) (1.0.4)\nRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from alembic<=1.4.1->mlflow) (2.8.1)\nRequirement already satisfied: tabulate>=0.7.7 in /opt/conda/lib/python3.7/site-packages (from databricks-cli>=0.8.7->mlflow) (0.8.9)\nRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from databricks-cli>=0.8.7->mlflow) (1.15.0)\nRequirement already satisfied: websocket-client>=0.32.0 in /opt/conda/lib/python3.7/site-packages (from docker>=4.0.0->mlflow) (0.57.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from gitpython>=2.1.0->mlflow) (4.0.7)\nRequirement already satisfied: smmap<5,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow) (3.0.5)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.17.3->mlflow) (1.26.4)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.17.3->mlflow) (2.10)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.17.3->mlflow) (2020.12.5)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.17.3->mlflow) (4.0.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from sqlalchemy->mlflow) (3.4.0)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.7/site-packages (from sqlalchemy->mlflow) (1.0.0)\nRequirement already satisfied: Werkzeug>=0.15 in /opt/conda/lib/python3.7/site-packages (from Flask->mlflow) (1.0.1)\nRequirement already satisfied: Jinja2>=2.10.1 in /opt/conda/lib/python3.7/site-packages (from Flask->mlflow) (2.11.3)\nRequirement already satisfied: itsdangerous>=0.24 in /opt/conda/lib/python3.7/site-packages (from Flask->mlflow) (1.1.0)\nRequirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from Jinja2>=2.10.1->Flask->mlflow) (1.1.1)\nRequirement already satisfied: setuptools>=3.0 in /opt/conda/lib/python3.7/site-packages (from gunicorn->mlflow) (49.6.0.post20210108)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->sqlalchemy->mlflow) (3.4.1)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->sqlalchemy->mlflow) (3.7.4.3)\nRequirement already satisfied: prometheus_client in /opt/conda/lib/python3.7/site-packages (from prometheus-flask-exporter->mlflow) (0.9.0)\nBuilding wheels for collected packages: alembic, databricks-cli, prometheus-flask-exporter\n  Building wheel for alembic (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158155 sha256=56d745ea43fa9b229d3a48cbcac9d0a59e2bd36d3b3dada2233df3b16c58deee\n  Stored in directory: /root/.cache/pip/wheels/be/5d/0a/9e13f53f4f5dfb67cd8d245bb7cdffe12f135846f491a283e3\n  Building wheel for databricks-cli (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for databricks-cli: filename=databricks_cli-0.14.3-py3-none-any.whl size=100555 sha256=dd649f6f1abf72f583cd1d35c657665adc60f7eb1ab728ccec24e207d7f3c08d\n  Stored in directory: /root/.cache/pip/wheels/3b/60/14/6930445b08959fbdf4e3029bac7e1f2cccb2e94df8afa00b29\n  Building wheel for prometheus-flask-exporter (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for prometheus-flask-exporter: filename=prometheus_flask_exporter-0.18.2-py3-none-any.whl size=17399 sha256=6d8636dba4a471dd6fb85a174490d72ca784f1096346fb8245abb8a1da98b8c2\n  Stored in directory: /root/.cache/pip/wheels/6a/1e/1c/c765920cb92b2f0343d2dd8b481a407cee2823f9b4bbd2e52a\nSuccessfully built alembic databricks-cli prometheus-flask-exporter\nInstalling collected packages: querystring-parser, prometheus-flask-exporter, gunicorn, databricks-cli, alembic, mlflow\n  Attempting uninstall: alembic\n    Found existing installation: alembic 1.5.8\n    Uninstalling alembic-1.5.8:\n      Successfully uninstalled alembic-1.5.8\nSuccessfully installed alembic-1.4.1 databricks-cli-0.14.3 gunicorn-20.1.0 mlflow-1.17.0 prometheus-flask-exporter-0.18.2 querystring-parser-1.2.4\n","output_type":"stream"}]},{"cell_type":"code","source":"# !pip install neptune\n# import neptune\n# run = neptune.init(project='railyavaliullina/DL-SOP-classification')","metadata":{"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\"\"\" config \"\"\"\n\ncfg = {\n    # parameters for dataset and dataloader\n    \"data\":\n        {\n            \"dataset_path\": '/kaggle/input/',\n            \"nb_train_images\": 71940,\n            \"nb_valid_images\": 24045,\n            \"nb_classes\": 12,\n            \"dataloader\": {\n                \"nb_epochs\": 20,\n                \"shuffle\": {\n                    \"train\": True,\n                    \"valid\": False\n                },\n                \"batch_size\": {\n                    \"train\": 128,\n                    \"valid\": 256\n                },\n            },\n            \"augmentation\":\n                {\n                    \"sz_crop\": 224,\n                    \"sz_resize\": 256,\n                    \"mean\": [0.485, 0.456, 0.406],\n                    \"std\": [0.229, 0.224, 0.225],\n                    \"contrast\": 0.4,\n                    \"saturation\": 0.4,\n                    \"brightness\": 0.4,\n                }\n        },\n\n    # parameters for ResNet-50 model parts\n    \"model\":\n        {\n            'pretrained':\n                {\n                    'load_pretrained': False,\n                    'url': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n                    'progress': True\n                },\n\n            'FirstConv':\n                {\n                    'in_channels': 3,\n                    'out_channels': 64,\n                    'kernel_size': 7,\n                    'stride': 2,\n                    'padding': 3,\n                    'bias': False\n                },\n            'MaxPool':\n                {\n                    'kernel_size': 3,\n                    'stride': 2,\n                    'padding': 1\n                },\n            'LayersGroup':\n                {\n                    # BottleNeck class common parameters\n                    'BottleNeck':\n                        {\n                            'kernel_size': [1, 3, 1],\n                            'padding': [0, 1, 0],\n                            'bias': False,\n                            'downsample':\n                                {\n                                    'kernel_size': 1,\n                                    'bias': False\n                                }\n                        },\n                    # layer group specific parameters\n                    'layer1': {\n                        'in_channels': 64,\n                        'out_channels': 64,\n                        'nb_layers': 3,\n                        'stride': 1\n                    },\n                    'layer2': {\n                        'in_channels': 256,\n                        'out_channels': 128,\n                        'nb_layers': 4,\n                        'stride': 2\n                    },\n                    'layer3': {\n                        'in_channels': 512,\n                        'out_channels': 256,\n                        'nb_layers': 6,\n                        'stride': 2\n                    },\n                    'layer4': {\n                        'in_channels': 1024,\n                        'out_channels': 512,\n                        'nb_layers': 3,\n                        'stride': 2\n                    }\n                },\n            'AvgPool':\n                {\n                    'output_size': (1, 1)\n                },\n            'Linear':\n                {\n                    'in_features': 2048,\n                    'out_features': 12,\n                    'bias': True\n                }\n        },\n\n    # parameters for setting up training parameters\n    \"train\":\n        {\n            # training stage common parameters\n            'epochs': 100,\n\n            # optimizer parameters\n            'opt':\n                {\n                    'optim_type': 'SGD',\n                    'learning_rate': 0.01,\n                    'momentum': 0.9,\n                    'weight_decay': 5e-4,\n                    'nesterov': True\n                }\n        },\n\n    # parameters for model evaluation\n    \"eval\":\n        {\n            'evaluate_on_train_data': False,\n            'evaluate_before_training': True,\n        },\n\n    # parameters for logging training process, saving/restoring model\n    \"logging\":\n        {\n            'log_metrics': True,\n            'experiment_name': 'baseline',\n            'checkpoints_dir': '/kaggle/input/checkpoints/',\n            'save_model': True,\n            'load_model': False,\n            'epoch_to_load': 20,\n            'save_frequency': 1,\n        },\n\n    # parameters to debug training and check if everything is ok\n    \"debug\":\n        {\n            # to check batches before training\n            \"save_batch\":\n                {\n                    \"enable\": False,\n                    \"nrof_batches_to_save\": 5,\n                    \"path_to_save\": '',\n                },\n            \"overfit_on_batch\":\n                {\n                    \"enable\": False,\n                    \"nb_iters\": 1000,\n                }\n        },\n}","metadata":{"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"\"\"\" data/dataset.py \"\"\"\n\nimport torch\nfrom torchvision import transforms as transforms_\nfrom torchvision.datasets import ImageFolder\nfrom collections import Counter\n\n\nclass SOPDataset(torch.utils.data.Dataset):\n    def __init__(self, cfg, dataset_type):\n        \"\"\"\n        Class for getting SOP dataset\n        :param cfg: cfg['data'] part of config\n        :param dataset_type: type of data ('train' or 'valid')\n        \"\"\"\n        cfg_aug = cfg['augmentation']\n        self.sz_crop = cfg_aug['sz_crop']\n        self.sz_resize = cfg_aug['sz_resize']\n        self.mean = cfg_aug['mean']\n        self.std = cfg_aug['std']\n        self.contrast = cfg_aug['contrast']\n        self.saturation = cfg_aug['saturation']\n        self.brightness = cfg_aug['brightness']\n\n        self.nb_classes = cfg['nb_classes']\n        self.dataset_type = dataset_type\n        # directory with all images\n        self.dataset_path = cfg['dataset_path'] + \"sop-\" + dataset_type + \"/\" + dataset_type + \"/\"\n\n        if dataset_type == 'train':\n            transforms = transforms_.Compose([\n                transforms_.RandomResizedCrop(self.sz_crop),\n                transforms_.RandomHorizontalFlip(),\n                transforms_.ColorJitter(contrast=self.contrast, saturation=self.saturation, brightness=self.brightness),\n                transforms_.ToTensor(),\n                transforms_.Normalize(\n                    mean=self.mean,\n                    std=self.std,\n                )\n            ])\n        elif dataset_type == 'valid':\n            transforms = transforms_.Compose([\n                    transforms_.Resize(self.sz_resize),\n                    transforms_.CenterCrop(self.sz_crop),\n                    transforms_.ToTensor(),\n                    transforms_.Normalize(\n                        mean=self.mean,\n                        std=self.std,\n                    )\n                ])\n        else:\n            raise Exception\n\n        print(f'Creating ImageFolder for {dataset_type} set...')\n        self.image_folder = ImageFolder(self.dataset_path, transforms)\n        self.image_folder.dataset_type = dataset_type\n        self.image_folder.nb_classes = cfg['nb_classes']\n        self.image_folder.labels = [sample[1] for sample in self.image_folder.samples]\n        self.image_folder.nb_images_per_class = Counter(np.asarray(self.image_folder.labels))\n\n        assert len(self.image_folder) == cfg[f'nb_{dataset_type}_images'], \\\n            f'Incorrect number of images in {dataset_type} set.'","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"\"\"\" data/dataloader.py \"\"\"\n\nfrom torch.utils.data import DataLoader\n# from data.dataset import SOPDataset\n\n\ndef get_dataloader(cfg, dataset_type):\n    \"\"\"\n    Get dataloader within dataset\n    :param cfg: cfg['data'] part of config\n    :param dataset: dataset to get dataloader from\n    :return: dataLoader\n    \"\"\"\n    dataset = SOPDataset(cfg, dataset_type)\n    dl = DataLoader(dataset.image_folder,\n                    batch_size=cfg['dataloader']['batch_size'][dataset_type],\n                    shuffle=cfg['dataloader']['shuffle'][dataset_type])\n    return dl","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\"\"\" models/resnet_model.py \"\"\"\n\nimport torch\nimport torch.nn as nn\nfrom torch.hub import load_state_dict_from_url\n\n\nclass FirstConv(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        \"\"\"\n        :param cfg: cfg['model']['FirstConv'] part of config\n        \"\"\"\n        self.in_channels = cfg['in_channels']\n        self.out_channels = cfg['out_channels']\n        self.kernel_size = cfg['kernel_size']\n        self.stride = cfg['stride']\n        self.padding = cfg['padding']\n        self.bias = cfg['bias']\n\n        self.conv = nn.Conv2d(in_channels=self.in_channels, out_channels=self.out_channels,\n                              kernel_size=self.kernel_size,\n                              stride=self.stride, padding=self.padding, bias=self.bias)\n        self.bn = nn.BatchNorm2d(self.out_channels)\n        self.relu = nn.ReLU(inplace=True)\n\n    def __call__(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = self.relu(x)\n        return x\n\n\nclass Bottleneck(nn.Module):\n    def __init__(self, cfg, in_channels, out_channels, stride=1, is_downsampling=False):\n        super(Bottleneck, self).__init__()\n        \"\"\"\n        :param cfg: cfg['model']['LayersGroup']['BottleNeck'] part of config\n        \"\"\"\n        self.kernel_size = cfg['kernel_size']\n        self.padding = cfg['padding']\n        self.bias = cfg['bias']\n\n        out_channels_2 = 4 * out_channels\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=self.kernel_size[0], padding=self.padding[0],\n                               bias=self.bias, stride=stride)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=self.kernel_size[1], padding=self.padding[1],\n                               bias=self.bias)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n\n        self.conv3 = nn.Conv2d(out_channels, out_channels_2, kernel_size=self.kernel_size[2], padding=self.padding[2],\n                               bias=self.bias)\n        self.bn3 = nn.BatchNorm2d(out_channels_2)\n        self.relu = nn.ReLU(inplace=True)\n        if is_downsampling:\n            self.downsample = nn.Sequential(*[nn.Conv2d(in_channels, out_channels_2,\n                                                        kernel_size=cfg['downsample']['kernel_size'], stride=stride,\n                                                        bias=cfg['downsample']['bias']), nn.BatchNorm2d(out_channels_2)])\n        else:\n            self.downsample = None\n\n    def forward(self, x):\n        identity = x\n        conv1 = self.relu(self.bn1(self.conv1(x)))\n        conv2 = self.relu(self.bn2(self.conv2(conv1)))\n        conv3 = self.bn3(self.conv3(conv2))\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out = conv3 + identity\n        return self.relu(out)\n\n\nclass LayersGroup(nn.Module):\n    def __init__(self, cfg, name):\n        super(LayersGroup, self).__init__()\n        \"\"\"\n        :param cfg: cfg['model']['LayersGroup'] part of config\n        :param name: name of current layer group\n        \"\"\"\n        self.in_channels = cfg[name]['in_channels']\n        self.out_channels = cfg[name]['out_channels']\n        self.nb_layers = cfg[name]['nb_layers']\n        self.stride = cfg[name]['stride']\n\n        self.out_channels_2 = 4 * self.out_channels\n        self.layers_group = [Bottleneck(cfg['BottleNeck'], self.in_channels, self.out_channels, stride=self.stride,\n                                        is_downsampling=True)]\n        for _ in range(1, self.nb_layers):\n            self.layers_group.append(Bottleneck(cfg['BottleNeck'], self.out_channels_2, self.out_channels))\n        self.layers_group = nn.Sequential(*self.layers_group)\n\n\nclass ResNet50(nn.Module):\n    def __init__(self, cfg):\n        super(ResNet50, self).__init__()\n        \"\"\"\n        Collects all parts of ResNet50 model\n        :param cfg: cfg['model'] part of config\n        \"\"\"\n        self.conv1 = FirstConv(cfg['FirstConv'])\n        self.maxpool = nn.MaxPool2d(kernel_size=cfg['MaxPool']['kernel_size'], stride=cfg['MaxPool']['stride'],\n                                    padding=cfg['MaxPool']['padding'])\n\n        self.layer1 = LayersGroup(cfg['LayersGroup'], name='layer1').layers_group\n        self.layer2 = LayersGroup(cfg['LayersGroup'], name='layer2').layers_group\n        self.layer3 = LayersGroup(cfg['LayersGroup'], name='layer3').layers_group\n        self.layer4 = LayersGroup(cfg['LayersGroup'], name='layer4').layers_group\n\n        self.avgpool = nn.AdaptiveAvgPool2d(output_size=cfg['AvgPool']['output_size'])\n        self.fc = nn.Linear(in_features=cfg['Linear']['in_features'], out_features=cfg['Linear']['out_features'],\n                            bias=cfg['Linear']['bias'])\n\n    def forward(self, x):\n        conv1 = self.conv1(x)\n        maxpool = self.maxpool(conv1)\n        layer1 = self.layer1(maxpool)\n        layer2 = self.layer2(layer1)\n        layer3 = self.layer3(layer2)\n        layer4 = self.layer4(layer3)\n        avgpool = self.avgpool(layer4)\n        fc = self.fc(torch.flatten(avgpool, 1))\n        return fc\n\n\ndef get_model(cfg):\n    \"\"\"\n    Gets ResNet-50 model\n    :param cfg: cfg['model'] part of config\n    :return: ResNet-50 model\n    \"\"\"\n    model = ResNet50(cfg)\n\n    nb_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    print(f'Trainable parameters number: {nb_trainable_params}')\n\n    if cfg['pretrained']['load_pretrained']:\n        print(f'Loading pretrained weights to initialize model...')\n        state_dict = load_state_dict_from_url(cfg['pretrained']['url'], progress=cfg['pretrained']['progress'])\n        model.load_state_dict(state_dict)\n    else:\n        print(f'Initializing weights with xavier uniform...')\n        model_parameters = model.parameters()\n        for i, param in enumerate(model_parameters):\n            if len(param.size()) == 4:\n                torch.nn.init.xavier_uniform_(param)\n    return model","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"\"\"\" utils/debug_utils.py \"\"\"\n\nimport torchvision\nimport torch\nimport numpy as np\n\n\ndef overfit_on_batch(cfg_overfit_on_batch, cfg_train, train_dl, model, optimizer, criterion):\n    \"\"\"\n    Overfits on one batch\n    :param cfg_overfit_on_batch: cfg['debug']['overfit_on_batch'] part of config\n    :param train_dl: train dataloader\n    :param model: resnet50 model\n    :param optimizer: optimizer\n    :param criterion: criterion\n    \"\"\"\n    train_dl = iter(train_dl)\n    images, labels = next(train_dl)\n    model = model.cuda()\n    accuracies = []\n\n    for iter_ in range(cfg_overfit_on_batch['nb_iters']):\n        optimizer.zero_grad()\n        logits = model(images.cuda()).cpu()\n        # calculate loss\n        cross_entropy_loss = criterion(logits, labels)\n        l2_reg = torch.tensor(0.0, requires_grad=True)\n        # for p in model.named_parameters():\n        #     if '.bias' not in p[0] and '.bn' not in p[0]:  # no biases or BN params\n        #         l2_reg = l2_reg + cfg_train['opt']['weight_decay'] * p[1].norm(2)\n        loss = cross_entropy_loss + l2_reg\n        # calculate accuracy\n        _, predicted = torch.max(logits.data, 1)\n        accuracy = torch.sum(predicted == labels).item() / labels.size(0) * 100\n        print(f'iter: {iter_}, acc: {accuracy}, cross_entropy_loss: {cross_entropy_loss.item()}, l2_reg: {l2_reg.item()}, '\n              f'total loss: {loss.item()}')\n\n        accuracies.append(accuracy)\n        if len(accuracies) >= 5 and np.min(accuracies[-5:]) == 100:\n            break\n\n        loss.backward()\n        optimizer.step()\n    print(f'Overfitting on batch is finished.')\n\n\ndef save_batch_images(cfg, train_dl, valid_dl):\n    \"\"\"\n    Saves several batches of images as .png file\n    :param cfg: cfg['debug']['save_batch'] part of config\n    :param train_dl: train dataloader to saves batches from\n    :param valid_dl: valid dataloader to saves batches from\n    \"\"\"\n    for dl in [train_dl, valid_dl]:\n        dataset_type = dl.dataset.dataset_type\n        print(dataset_type)\n        dl = iter(dl)\n        for i in range(cfg['nrof_batches_to_save']):\n            images, labels = next(dl)\n            print(f'batch {i} labels: {labels}')\n            torchvision.utils.save_image(images, cfg['path_to_save'] + f'{dataset_type}_batch_{i}.png')","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"\"\"\" utils/eval_utils.py \"\"\"\n\nimport time\nimport numpy as np\nimport torch\n\n# from utils.log_utils import log_metrics\n\n\ndef evaluate(cfg_train, cfg_logging, model, dl, epoch, dataset_type, criterion):\n    \"\"\"\n    Evaluates on train/valid data\n    :param cfg_eval: cfg['train'] part of config\n    :param cfg_logging: cfg['logging'] part of config\n    :param model: resnet-50 model\n    :param dl: train/valid dataloader\n    :param epoch: epoch for logging\n    :param dataset_type: type of current data ('train' or 'valid')\n    \"\"\"\n    print(f'Evaluating on {dataset_type} data...')\n    eval_start_time = time.time()\n    correct, total = 0, 0\n    cross_entropy_losses, reg_losses, losses = [], [], []\n    unique_labels = np.unique(dl.dataset.labels)\n    accuracies_for_classes = [0 for _ in unique_labels]\n    model = model.cuda()\n\n    dl_len = len(dl)\n    for i, (images, labels) in enumerate(dl):\n        images, labels = images.cuda(), labels.cuda()\n\n        if i % 50 == 0:\n            print(f'iter: {i}/{dl_len}')\n\n        logits = model(images)\n        _, predicted = torch.max(logits.data, 1)\n        total += labels.size(0)\n        correct += torch.sum(predicted == labels)\n\n        for i, l in enumerate(labels):\n            accuracies_for_classes[l] += torch.sum((predicted[i] == l))\n\n        # calculate losses\n        cross_entropy_loss = criterion(logits, labels)\n        cross_entropy_losses.append(cross_entropy_loss.item())\n        l2_reg = torch.tensor(0.0, requires_grad=True)\n        for p in model.parameters():\n            l2_reg = l2_reg + cfg_train['opt']['weight_decay'] * p.norm(2)\n        reg_losses.append(l2_reg.item())\n        losses.append((cross_entropy_loss + l2_reg).item())\n\n    log_metrics([f'{dataset_type}_eval/cross_entropy_loss', f'{dataset_type}_eval/reg_loss_train',\n                 f'{dataset_type}_eval/total_loss_train'],\n                [np.mean(cross_entropy_losses), np.mean(reg_losses), np.mean(losses)], epoch, cfg_logging)\n\n    accuracy = 100 * correct.item() / total\n    print(f'Accuracy on {dataset_type} data: {accuracy}')\n    accuracies_for_classes = [100 * acc.item() / dl.dataset.nb_images_per_class[i] for i, acc in\n                              enumerate(accuracies_for_classes)]\n    print(f'accuracies for classes: {accuracies_for_classes}')\n    balanced_acc = sum(accuracies_for_classes) / dl.dataset.nb_classes\n    print(f'Balanced accuracy: {balanced_acc}')\n\n    for i, acc in enumerate(accuracies_for_classes):\n        log_metrics([f'{dataset_type}_eval/accuracy_class_{i}'], [acc], epoch, cfg_logging)\n\n    log_metrics([f'{dataset_type}_eval/accuracy', f'{dataset_type}_eval/balanced_accuracy'], [accuracy, balanced_acc],\n                epoch, cfg_logging)\n    print(f'Evaluating time: {round((time.time() - eval_start_time) / 60, 3)} min')","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"\"\"\" utils/log_utils.py \"\"\"\n\nimport mlflow\n\n\ndef start_logging(cfg, experiment_name=None):\n    \"\"\"\n    Starts mlflow logging\n    :param cfg: cfg['logging'] part of config\n    :param experiment_name: experiment name for mlflow visualization\n    \"\"\"\n    if cfg['log_metrics']:\n        experiment_name = cfg['train']['experiment_name'] if experiment_name is None else experiment_name\n        mlflow.start_run(run_name=experiment_name)\n\n\ndef end_logging(cfg):\n    \"\"\"\n    Finishes mlflow logging\n    :param cfg: cfg['logging'] part of config\n    \"\"\"\n    if cfg['log_metrics']:\n        mlflow.end_run()\n\n\ndef log_metrics(names, metrics, step, cfg):\n    \"\"\"\n    Logs metrics in given list with corresponding names\n    :param names: list of names of given metrics\n    :param metrics: list of given metrics\n    :param step: step to log\n    :param cfg: cfg['logging'] part of config\n    \"\"\"\n    if cfg['log_metrics']:\n        for name, metric in zip(names, metrics):\n            mlflow.log_metric(name, metric, step)\n\n\ndef log_params(cfg):\n    \"\"\"\n    Logs experiment config with all parameters\n    :param cfg: cfg['logging'] part of config\n    \"\"\"\n    if cfg['log_metrics']:\n        mlflow.log_param('cfg', cfg)\n","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"\"\"\" utils/train_utils.py \"\"\"\n\nimport torch\n\n\ndef get_optimizer(cfg, model):\n    \"\"\"\n    Gets optimizer for parameters update\n    :param cfg: cfg['train']['opt'] part of config\n    :param model: ResNet-50 model\n    :return: optimizer\n    \"\"\"\n    if cfg['optim_type'] == 'SGD':\n        opt = torch.optim.SGD(params=model.parameters(),\n                              lr=cfg['learning_rate'],\n                              momentum=cfg['momentum'],\n                              weight_decay=cfg['weight_decay'],\n                              nesterov=cfg['nesterov'])\n    else:\n        raise Exception\n    return opt\n\n\ndef get_criterion():\n    \"\"\"\n    Gets loss function\n    :return: loss function\n    \"\"\"\n    criterion = torch.nn.CrossEntropyLoss()\n    return criterion\n\n\ndef make_training_step(cfg_train, batch, model, criterion, optimizer):\n    \"\"\"\n    Makes single parameters updating step.\n    :param cfg_train: cfg['train'] part of config\n    :param batch: current batch\n    :param model: resnet50 model\n    :param criterion: criterion\n    :param optimizer: optimizer\n    :param iter_: current iteration\n    :return: current loss value\n    \"\"\"\n    images, labels = batch\n    images, labels, model = images.cuda(), labels.cuda(), model.cuda()\n    optimizer.zero_grad()\n    logits = model(images)\n    cross_entropy_loss = criterion(logits, labels)\n    l2_reg = torch.tensor(0.0, requires_grad=True)\n    # for p in model.named_parameters():\n    #     if '.bias' not in p[0] and '.bn' not in p[0]:  # no biases or BN params\n    #         l2_reg = l2_reg + cfg_train['opt']['weight_decay'] * p[1].norm(2)\n    loss = cross_entropy_loss + l2_reg\n    loss.backward()\n    optimizer.step()\n    return loss.item(), l2_reg.item(), cross_entropy_loss.item()","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"\"\"\" train/main.py \"\"\"\n\nimport time\nimport numpy as np\nimport torch\nimport tarfile\nimport os\n\n# from data.dataloader import get_dataloader\n# from utils.train_utils import get_optimizer, get_criterion, make_training_step\n# from utils.eval_utils import evaluate\n# from utils.debug_utils import save_batch_images, overfit_on_batch\n# from utils.log_utils import start_logging, end_logging, log_metrics, log_params\n# from models.resnet_model import get_model\n# from configs.config import cfg\n\n\ndef train(cfg, train_dl, valid_dl, model, opt, criterion):\n\n    # check data before training\n    if cfg['debug']['save_batch']['enable']:\n        save_batch_images(cfg['debug']['save_batch'], train_dl, valid_dl)\n\n    # check training procedure before training\n    if cfg['debug']['overfit_on_batch']['enable']:\n        overfit_on_batch(cfg['debug']['overfit_on_batch'], cfg['train'], train_dl, model, opt, criterion)\n\n    # save experiment name and experiment params to mlflow\n    start_logging(cfg['logging'], experiment_name='baseline')\n    log_params(cfg['logging'])\n\n    global_step, start_epoch = 0, 0\n    if cfg['logging']['load_model']:\n        print(f'Trying to load checkpoint from epoch {cfg[\"logging\"][\"epoch_to_load\"]}...')\n        checkpoint = torch.load(cfg['logging']['checkpoints_dir'] + f'checkpoint_{cfg[\"logging\"][\"epoch_to_load\"]}.pth')\n        load_state_dict = checkpoint['model']\n        model.load_state_dict(load_state_dict)\n        start_epoch = checkpoint['epoch'] + 1\n        global_step = checkpoint['global_step'] + 1\n        print(f'Successfully loaded checkpoint from epoch {cfg[\"logging\"][\"epoch_to_load\"]}.')\n\n    # evaluate on train and test data before training\n    if cfg['eval']['evaluate_before_training']:\n        model.eval()\n        with torch.no_grad():\n            if cfg['eval']['evaluate_on_train_data']:\n                evaluate(cfg['train'], cfg['logging'], model, train_dl, -1, 'train', criterion)\n            evaluate(cfg['train'], cfg['logging'], model, valid_dl, -1, 'valid', criterion)\n        model.train()\n\n    nb_iters_per_epoch = len(train_dl.dataset) // train_dl.batch_size\n\n    # training loop\n    for epoch in range(start_epoch, cfg['train']['epochs']):\n        losses, reg_losses, cross_entropy_losses = [], [], []\n        epoch_start_time = time.time()\n        print(f'Epoch: {epoch}')\n        for iter_, batch in enumerate(train_dl):\n            loss, reg_loss, cross_entropy_loss = make_training_step(cfg['train'], batch, model, criterion, opt)\n            losses.append(loss)\n            reg_losses.append(reg_loss)\n            cross_entropy_losses.append(cross_entropy_loss)\n            global_step += 1\n\n            log_metrics(['train/loss', 'train/reg_loss', 'train/cross_entropy_loss'], [loss, reg_loss, cross_entropy_loss],\n                        global_step, cfg['logging'])\n\n            if global_step % 100 == 0:\n                mean_loss = np.mean(losses[:-20]) if len(losses) > 20 else np.mean(losses)\n                mean_reg_loss = np.mean(reg_losses[:-20]) if len(reg_losses) > 20 else np.mean(reg_losses)\n                mean_cross_entropy_loss = np.mean(cross_entropy_losses[:-20]) if len(cross_entropy_losses) > 20 \\\n                    else np.mean(cross_entropy_losses)\n                print(f'step: {global_step}, total_loss: {mean_loss}, cross_entropy_loss: {mean_cross_entropy_loss}, '\n                      f'reg_loss: {mean_reg_loss}')\n\n        # log mean loss per epoch\n        log_metrics(['train/mean_loss'], [np.mean(losses[:-nb_iters_per_epoch])], epoch, cfg['logging'])\n        print(f'Epoch time: {round((time.time() - epoch_start_time) / 60, 3)} min')\n\n        # save model\n        if cfg['logging']['save_model'] and epoch % cfg['logging']['save_frequency'] == 0:\n            print('Saving current model...')\n            state = {\n                'model': model.state_dict(),\n                'epoch': epoch,\n                'global_step': global_step,\n                'opt': opt.state_dict(),\n            }\n            torch.save(state, f'checkpoint_{epoch}.pth')\n\n        # save mlruns as tarfile\n        files_to_save = os.listdir('/kaggle/working/')\n        tar = tarfile.open(f'mlruns_epoch_{epoch}.tar.gz', 'w:gz')\n        for item in files_to_save:\n            if item.startswith('mlruns') and not item.startswith('mlruns_epoch'):\n                tar.add(item)\n        tar.close()\n\n        # evaluate on train and test data\n        model.eval()\n        with torch.no_grad():\n            if cfg['eval']['evaluate_on_train_data']:\n                evaluate(cfg['train'], cfg['logging'], model, train_dl, epoch, 'train', criterion)\n            evaluate(cfg['train'], cfg['logging'], model, valid_dl, epoch, 'valid', criterion)\n        model.train()\n\n    end_logging(cfg['logging'])\n\n\ndef run(cfg):\n    train_dl = get_dataloader(cfg['data'], 'train')\n    valid_dl = get_dataloader(cfg['data'], 'valid')\n\n    model = get_model(cfg['model'])\n    opt = get_optimizer(cfg['train']['opt'], model)\n    criterion = get_criterion()\n\n    # run training\n    train(cfg, train_dl, valid_dl, model, opt, criterion)\n\n\nif __name__ == '__main__':\n    start_time = time.time()\n    run(cfg)\n    print(f'Total time: {round((time.time() - start_time) / 60, 3)} min')","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Creating ImageFolder for train set...\nCreating ImageFolder for valid set...\nTrainable parameters number: 23532620\nInitializing weights with xavier uniform...\nEvaluating on valid data...\niter: 0/94\niter: 50/94\nAccuracy on valid data: 11.524225410688294\naccuracies for classes: [0.0, 0.0, 0.0, 0.0, 0.0, 9.328726554787758, 0.0, 94.68280161349469, 0.0, 0.0, 0.0, 0.0]\nBalanced accuracy: 8.667627347356872\nEvaluating time: 5.252 min\nEpoch: 0\nstep: 100, total_loss: 2.8380133479833605, cross_entropy_loss: 2.8380133479833605, reg_loss: 0.0\nstep: 200, total_loss: 2.6127919528219437, cross_entropy_loss: 2.6127919528219437, reg_loss: 0.0\nstep: 300, total_loss: 2.5220432571002416, cross_entropy_loss: 2.5220432571002416, reg_loss: 0.0\nstep: 400, total_loss: 2.47405909174367, cross_entropy_loss: 2.47405909174367, reg_loss: 0.0\nstep: 500, total_loss: 2.4401849458614984, cross_entropy_loss: 2.4401849458614984, reg_loss: 0.0\nEpoch time: 23.958 min\nSaving current model...\nEvaluating on valid data...\niter: 0/94\niter: 50/94\nAccuracy on valid data: 12.875857766687462\naccuracies for classes: [14.491882140709562, 0.0, 86.96731485312371, 0.1029336078229542, 0.0, 0.0, 0.0, 24.055738907224057, 0.0, 0.0, 0.0, 5.437893531768746]\nBalanced accuracy: 10.921313586720752\nEvaluating time: 3.314 min\nEpoch: 1\nstep: 600, total_loss: 2.444325362934786, cross_entropy_loss: 2.444325362934786, reg_loss: 0.0\nstep: 700, total_loss: 2.2687945834591856, cross_entropy_loss: 2.2687945834591856, reg_loss: 0.0\nstep: 800, total_loss: 2.2406192792725452, cross_entropy_loss: 2.2406192792725452, reg_loss: 0.0\nstep: 900, total_loss: 2.2219201510636966, cross_entropy_loss: 2.2219201510636966, reg_loss: 0.0\nstep: 1000, total_loss: 2.204123355501847, cross_entropy_loss: 2.204123355501847, reg_loss: 0.0\nstep: 1100, total_loss: 2.185725549203515, cross_entropy_loss: 2.185725549203515, reg_loss: 0.0\nEpoch time: 18.015 min\nSaving current model...\nEvaluating on valid data...\niter: 0/94\niter: 50/94\nAccuracy on valid data: 23.040133083801205\naccuracies for classes: [42.69392663860493, 72.76859504132231, 0.0, 1.6984045290787442, 56.916666666666664, 5.577492596248766, 28.37190742218675, 46.93802713604694, 6.653225806451613, 8.84272997032641, 0.0, 0.057240984544934176]\nBalanced accuracy: 22.54318473262317\nEvaluating time: 3.309 min\nEpoch: 2\nstep: 1200, total_loss: 2.1358733199260853, cross_entropy_loss: 2.1358733199260853, reg_loss: 0.0\nstep: 1300, total_loss: 2.0898087752329837, cross_entropy_loss: 2.0898087752329837, reg_loss: 0.0\nstep: 1400, total_loss: 2.064034157381283, cross_entropy_loss: 2.064034157381283, reg_loss: 0.0\nstep: 1500, total_loss: 2.043590146943001, cross_entropy_loss: 2.043590146943001, reg_loss: 0.0\nstep: 1600, total_loss: 2.027770079442583, cross_entropy_loss: 2.027770079442583, reg_loss: 0.0\nEpoch time: 18.023 min\nSaving current model...\nEvaluating on valid data...\niter: 0/94\niter: 50/94\nAccuracy on valid data: 27.419421917238513\naccuracies for classes: [83.82441371016236, 44.33884297520661, 0.9515928837401738, 4.632012352032938, 42.0, 11.303060217176704, 6.344772545889865, 29.996332966629996, 65.5241935483871, 0.3560830860534125, 50.247413405308144, 11.734401831711505]\nBalanced accuracy: 29.2710932935249\nEvaluating time: 3.301 min\nEpoch: 3\nstep: 1700, total_loss: 2.090782555666837, cross_entropy_loss: 2.090782555666837, reg_loss: 0.0\nstep: 1800, total_loss: 1.9475596448877355, cross_entropy_loss: 1.9475596448877355, reg_loss: 0.0\nstep: 1900, total_loss: 1.9171725848582402, cross_entropy_loss: 1.9171725848582402, reg_loss: 0.0\nstep: 2000, total_loss: 1.8917434109035636, cross_entropy_loss: 1.8917434109035636, reg_loss: 0.0\nstep: 2100, total_loss: 1.8768197032801635, cross_entropy_loss: 1.8768197032801635, reg_loss: 0.0\nstep: 2200, total_loss: 1.8629586220758754, cross_entropy_loss: 1.8629586220758754, reg_loss: 0.0\nEpoch time: 18.039 min\nSaving current model...\nEvaluating on valid data...\niter: 0/94\niter: 50/94\nAccuracy on valid data: 16.589727594094406\naccuracies for classes: [92.72399278412507, 78.22314049586777, 0.12412081092263136, 1.8013381369016983, 0.5833333333333334, 0.5923000987166831, 3.830806065442937, 7.920792079207921, 11.559139784946236, 0.3560830860534125, 0.0, 0.4006868918145392]\nBalanced accuracy: 16.509644463944355\nEvaluating time: 3.336 min\nEpoch: 4\nstep: 2300, total_loss: 2.192938025508608, cross_entropy_loss: 2.192938025508608, reg_loss: 0.0\nstep: 2400, total_loss: 1.9122233921661973, cross_entropy_loss: 1.9122233921661973, reg_loss: 0.0\nstep: 2500, total_loss: 1.8458320754661894, cross_entropy_loss: 1.8458320754661894, reg_loss: 0.0\nstep: 2600, total_loss: 1.813622104685481, cross_entropy_loss: 1.813622104685481, reg_loss: 0.0\nstep: 2700, total_loss: 1.7876289712491436, cross_entropy_loss: 1.7876289712491436, reg_loss: 0.0\nstep: 2800, total_loss: 1.7624592744942866, cross_entropy_loss: 1.7624592744942866, reg_loss: 0.0\nEpoch time: 18.194 min\nSaving current model...\nEvaluating on valid data...\niter: 0/94\niter: 50/94\nAccuracy on valid data: 28.667082553545434\naccuracies for classes: [92.0625375826819, 22.479338842975206, 27.347952006619778, 2.4704065877509005, 28.416666666666668, 32.477788746298124, 40.86193136472466, 46.864686468646866, 22.379032258064516, 15.786350148367953, 7.60233918128655, 2.289639381797367]\nBalanced accuracy: 28.419889102990037\nEvaluating time: 3.304 min\nEpoch: 5\nstep: 2900, total_loss: 1.8002689599990844, cross_entropy_loss: 1.8002689599990844, reg_loss: 0.0\nstep: 3000, total_loss: 1.7159907247080948, cross_entropy_loss: 1.7159907247080948, reg_loss: 0.0\nstep: 3100, total_loss: 1.6845063740352415, cross_entropy_loss: 1.6845063740352415, reg_loss: 0.0\nstep: 3200, total_loss: 1.6675478722951182, cross_entropy_loss: 1.6675478722951182, reg_loss: 0.0\nstep: 3300, total_loss: 1.6510189881888768, cross_entropy_loss: 1.6510189881888768, reg_loss: 0.0\nEpoch time: 18.437 min\nSaving current model...\nEvaluating on valid data...\niter: 0/94\niter: 50/94\nAccuracy on valid data: 34.29403202328967\naccuracies for classes: [83.94467829224294, 26.239669421487605, 12.660322714108398, 72.67112712300566, 27.166666666666668, 8.094768015794669, 6.0654429369513165, 49.76164283094976, 27.688172043010752, 17.863501483679524, 70.94017094017094, 11.906124785346307]\nBalanced accuracy: 34.58352393778454\nEvaluating time: 3.302 min\nEpoch: 6\nstep: 3400, total_loss: 2.1308480501174927, cross_entropy_loss: 2.1308480501174927, reg_loss: 0.0\nstep: 3500, total_loss: 1.649421520092908, cross_entropy_loss: 1.649421520092908, reg_loss: 0.0\nstep: 3600, total_loss: 1.6096352828611242, cross_entropy_loss: 1.6096352828611242, reg_loss: 0.0\nstep: 3700, total_loss: 1.5896265190958188, cross_entropy_loss: 1.5896265190958188, reg_loss: 0.0\nstep: 3800, total_loss: 1.5770580910924654, cross_entropy_loss: 1.5770580910924654, reg_loss: 0.0\nstep: 3900, total_loss: 1.5683814707505275, cross_entropy_loss: 1.5683814707505275, reg_loss: 0.0\nEpoch time: 18.633 min\nSaving current model...\nEvaluating on valid data...\niter: 0/94\niter: 50/94\nAccuracy on valid data: 34.913703472655435\naccuracies for classes: [31.26879134095009, 69.3801652892562, 47.82788580885395, 7.153885743695317, 25.25, 25.024679170779862, 53.63128491620112, 28.126145947928126, 49.596774193548384, 3.3234421364985165, 5.578047683310841, 60.789925586720095]\nBalanced accuracy: 33.912585651478544\nEvaluating time: 3.316 min\nEpoch: 7\nstep: 4000, total_loss: 1.6167062398714898, cross_entropy_loss: 1.6167062398714898, reg_loss: 0.0\nstep: 4100, total_loss: 1.5311760730880628, cross_entropy_loss: 1.5311760730880628, reg_loss: 0.0\nstep: 4200, total_loss: 1.5121713776967516, cross_entropy_loss: 1.5121713776967516, reg_loss: 0.0\nstep: 4300, total_loss: 1.5015523760719638, cross_entropy_loss: 1.5015523760719638, reg_loss: 0.0\nstep: 4400, total_loss: 1.4935664288818429, cross_entropy_loss: 1.4935664288818429, reg_loss: 0.0\nstep: 4500, total_loss: 1.489214928782716, cross_entropy_loss: 1.489214928782716, reg_loss: 0.0\nEpoch time: 18.638 min\nSaving current model...\nEvaluating on valid data...\niter: 0/94\niter: 50/94\nAccuracy on valid data: 51.025161156165524\naccuracies for classes: [90.79975947083584, 77.85123966942149, 32.97476210177906, 48.481729284611426, 53.25, 64.11648568608095, 31.92338387869114, 77.3010634396773, 82.3252688172043, 35.19287833827893, 6.612685560053981, 18.603319977103606]\nBalanced accuracy: 51.61938135197817\nEvaluating time: 3.308 min\nEpoch: 8\nstep: 4600, total_loss: 1.4704467026810897, cross_entropy_loss: 1.4704467026810897, reg_loss: 0.0\nstep: 4700, total_loss: 1.443296330896291, cross_entropy_loss: 1.443296330896291, reg_loss: 0.0\nstep: 4800, total_loss: 1.4357445378234421, cross_entropy_loss: 1.4357445378234421, reg_loss: 0.0\nstep: 4900, total_loss: 1.434402658267224, cross_entropy_loss: 1.434402658267224, reg_loss: 0.0\nstep: 5000, total_loss: 1.4259628322945923, cross_entropy_loss: 1.4259628322945923, reg_loss: 0.0\nEpoch time: 18.486 min\nSaving current model...\nEvaluating on valid data...\niter: 0/94\niter: 50/94\nAccuracy on valid data: 34.60178831357871\naccuracies for classes: [93.26518340348767, 36.77685950413223, 37.815473727761685, 39.063304168811115, 33.833333333333336, 27.88746298124383, 20.989624900239427, 44.95782911624496, 18.010752688172044, 54.896142433234424, 9.7165991902834, 4.235832856325128]\nBalanced accuracy: 35.120699858605775\nEvaluating time: 3.314 min\nEpoch: 9\nstep: 5100, total_loss: 1.7567775616279016, cross_entropy_loss: 1.7567775616279016, reg_loss: 0.0\nstep: 5200, total_loss: 1.5103568250099115, cross_entropy_loss: 1.5103568250099115, reg_loss: 0.0\nstep: 5300, total_loss: 1.4652155570580925, cross_entropy_loss: 1.4652155570580925, reg_loss: 0.0\nstep: 5400, total_loss: 1.4430549030486768, cross_entropy_loss: 1.4430549030486768, reg_loss: 0.0\nstep: 5500, total_loss: 1.4263281380581798, cross_entropy_loss: 1.4263281380581798, reg_loss: 0.0\nstep: 5600, total_loss: 1.413598610643755, cross_entropy_loss: 1.413598610643755, reg_loss: 0.0\nEpoch time: 18.048 min\nSaving current model...\nEvaluating on valid data...\niter: 0/94\niter: 50/94\nAccuracy on valid data: 47.743813682678315\naccuracies for classes: [55.80276608538785, 79.75206611570248, 76.83078196110881, 35.409161091096244, 52.916666666666664, 66.83119447186574, 21.74780526735834, 50.05500550055005, 70.02688172043011, 29.73293768545994, 17.498875393612234, 14.081282198053806]\nBalanced accuracy: 47.557118679774355\nEvaluating time: 3.307 min\nEpoch: 10\nstep: 5700, total_loss: 1.4728896856307983, cross_entropy_loss: 1.4728896856307983, reg_loss: 0.0\nstep: 5800, total_loss: 1.4056134724617004, cross_entropy_loss: 1.4056134724617004, reg_loss: 0.0\nstep: 5900, total_loss: 1.3771144547462464, cross_entropy_loss: 1.3771144547462464, reg_loss: 0.0\nstep: 6000, total_loss: 1.3678408019883292, cross_entropy_loss: 1.3678408019883292, reg_loss: 0.0\nstep: 6100, total_loss: 1.363934866057502, cross_entropy_loss: 1.363934866057502, reg_loss: 0.0\nEpoch time: 17.974 min\nSaving current model...\nEvaluating on valid data...\niter: 0/94\niter: 50/94\nAccuracy on valid data: 40.21210230817218\naccuracies for classes: [61.69573060733614, 41.19834710743802, 26.43773272652048, 24.395265054040145, 32.0, 37.95656465942744, 63.92657621707901, 67.76677667766776, 65.79301075268818, 23.14540059347181, 13.990103463787674, 14.310246136233543]\nBalanced accuracy: 39.38464616630752\nEvaluating time: 3.319 min\nEpoch: 11\nstep: 6200, total_loss: 1.6715133019856043, cross_entropy_loss: 1.6715133019856043, reg_loss: 0.0\nstep: 6300, total_loss: 1.3957316505497899, cross_entropy_loss: 1.3957316505497899, reg_loss: 0.0\nstep: 6400, total_loss: 1.3509308584233657, cross_entropy_loss: 1.3509308584233657, reg_loss: 0.0\nstep: 6500, total_loss: 1.3395069023457968, cross_entropy_loss: 1.3395069023457968, reg_loss: 0.0\nstep: 6600, total_loss: 1.3340192001303346, cross_entropy_loss: 1.3340192001303346, reg_loss: 0.0\nstep: 6700, total_loss: 1.3281970293370116, cross_entropy_loss: 1.3281970293370116, reg_loss: 0.0\nEpoch time: 18.046 min\nSaving current model...\nEvaluating on valid data...\niter: 0/94\niter: 50/94\nAccuracy on valid data: 15.2131420253691\naccuracies for classes: [5.051112447384245, 52.64462809917355, 3.5581299131154323, 13.484302624807, 42.416666666666664, 1.2339585389930898, 22.067039106145252, 12.504583791712504, 7.594086021505376, 4.629080118694362, 10.07647323436797, 6.239267315397825]\nBalanced accuracy: 15.124943989830271\nEvaluating time: 3.313 min\nEpoch: 12\nstep: 6800, total_loss: 1.6878834118445714, cross_entropy_loss: 1.6878834118445714, reg_loss: 0.0\nstep: 6900, total_loss: 1.4805730927375056, cross_entropy_loss: 1.4805730927375056, reg_loss: 0.0\nstep: 7000, total_loss: 1.4339748759354864, cross_entropy_loss: 1.4339748759354864, reg_loss: 0.0\nstep: 7100, total_loss: 1.3992737859119604, cross_entropy_loss: 1.3992737859119604, reg_loss: 0.0\nstep: 7200, total_loss: 1.3739456469720264, cross_entropy_loss: 1.3739456469720264, reg_loss: 0.0\nstep: 7300, total_loss: 1.3564850104446629, cross_entropy_loss: 1.3564850104446629, reg_loss: 0.0\nEpoch time: 18.032 min\nSaving current model...\nEvaluating on valid data...\niter: 0/94\niter: 50/94\nAccuracy on valid data: 50.05198585984612\naccuracies for classes: [46.001202645820804, 60.66115702479339, 35.74679354571783, 42.30571281523417, 35.666666666666664, 50.54294175715696, 49.92019154030327, 81.37147048038138, 83.40053763440861, 29.43620178041543, 43.31983805668016, 28.27704636519748]\nBalanced accuracy: 48.88748002606469\nEvaluating time: 3.282 min\nEpoch: 13\nstep: 7400, total_loss: 1.4081022817580426, cross_entropy_loss: 1.4081022817580426, reg_loss: 0.0\nstep: 7500, total_loss: 1.3338218534955326, cross_entropy_loss: 1.3338218534955326, reg_loss: 0.0\nstep: 7600, total_loss: 1.31187417635059, cross_entropy_loss: 1.31187417635059, reg_loss: 0.0\nstep: 7700, total_loss: 1.3028950212404669, cross_entropy_loss: 1.3028950212404669, reg_loss: 0.0\nstep: 7800, total_loss: 1.2903821677809941, cross_entropy_loss: 1.2903821677809941, reg_loss: 0.0\nEpoch time: 18.017 min\nSaving current model...\nEvaluating on valid data...\niter: 0/94\niter: 50/94\nAccuracy on valid data: 52.613849033063005\naccuracies for classes: [76.24774503908598, 60.6198347107438, 34.505585436491515, 49.45959855892949, 78.08333333333333, 52.61599210266535, 42.2585794094174, 68.75687568756875, 60.685483870967744, 48.84272997032641, 36.75213675213675, 36.6914710933028]\nBalanced accuracy: 53.79328049708078\nEvaluating time: 3.306 min\nEpoch: 14\nstep: 7900, total_loss: 1.385238594479031, cross_entropy_loss: 1.385238594479031, reg_loss: 0.0\nstep: 8000, total_loss: 1.2960468822596025, cross_entropy_loss: 1.2960468822596025, reg_loss: 0.0\nstep: 8100, total_loss: 1.2664590568253489, cross_entropy_loss: 1.2664590568253489, reg_loss: 0.0\nstep: 8200, total_loss: 1.2662744122063554, cross_entropy_loss: 1.2662744122063554, reg_loss: 0.0\nstep: 8300, total_loss: 1.2550573031506946, cross_entropy_loss: 1.2550573031506946, reg_loss: 0.0\nstep: 8400, total_loss: 1.2491352105715188, cross_entropy_loss: 1.2491352105715188, reg_loss: 0.0\n","output_type":"stream"}]}]}